{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-21T12:26:39.042720Z",
     "iopub.status.busy": "2020-11-21T12:26:39.041921Z",
     "iopub.status.idle": "2020-11-21T12:26:43.366502Z",
     "shell.execute_reply": "2020-11-21T12:26:43.365929Z"
    },
    "papermill": {
     "duration": 4.347604,
     "end_time": "2020-11-21T12:26:43.366619",
     "exception": false,
     "start_time": "2020-11-21T12:26:39.019015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import keras.utils as image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017945,
     "end_time": "2020-11-21T12:26:43.403397",
     "exception": false,
     "start_time": "2020-11-21T12:26:43.385452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extracting Features from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-21T12:26:43.450282Z",
     "iopub.status.busy": "2020-11-21T12:26:43.449609Z",
     "iopub.status.idle": "2020-11-21T12:26:49.118020Z",
     "shell.execute_reply": "2020-11-21T12:26:49.117097Z"
    },
    "papermill": {
     "duration": 5.696821,
     "end_time": "2020-11-21T12:26:49.118138",
     "exception": false,
     "start_time": "2020-11-21T12:26:43.421317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize Model\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "#Define Function to extract Features\n",
    "def extract_features(img_path, model):\n",
    "    \n",
    "    #Preprocessing Input Image\n",
    "    input_shape = (224, 224, 3)\n",
    "    img = image.load_img(img_path, target_size=(input_shape[0], input_shape[1])) #Reshape input image size into target size\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    \n",
    "    #Getting features from the Image\n",
    "    features = model.predict(preprocessed_img)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features = flattened_features / norm(flattened_features)\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024689,
     "end_time": "2020-11-21T12:26:49.167040",
     "exception": false,
     "start_time": "2020-11-21T12:26:49.142351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "****Explaination of the above code:****\n",
    "\n",
    "1.  This loads an image and resizes the image to (224, 224): img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "2.  The img_to_array() function adds channels: x.shape = (224, 224, 3) for RGB and (224, 224, 1) for gray image:          x = image.img_to_array(img) \n",
    "\n",
    "3.  expand_dims() is used to add the number of images: x.shape = (1, 224, 224, 3): x = np.expand_dims(x, axis=0)\n",
    "\n",
    "4.  preprocess_input subtracts the mean RGB channels of the imagenet dataset. This is because the model you are using has     been trained on a different dataset: x.shape is still (1, 224, 224, 3): x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023724,
     "end_time": "2020-11-21T12:26:49.215832",
     "exception": false,
     "start_time": "2020-11-21T12:26:49.192108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **numpy.linalg.norm**: This function returns one of the seven matrix norms or one of the infinite vector norms depending upon the value of its parameters.\n",
    "* **preprocess_input**: The preprocess_input function is meant to adequate your image to the format the model requires.Some models use images with values ranging from 0 to 1. Others from -1 to +1. Others use the \"caffe\" style, that is not normalized, but is centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:26:49.271882Z",
     "iopub.status.busy": "2020-11-21T12:26:49.271156Z",
     "iopub.status.idle": "2020-11-21T12:26:49.274100Z",
     "shell.execute_reply": "2020-11-21T12:26:49.274566Z"
    },
    "papermill": {
     "duration": 0.03536,
     "end_time": "2020-11-21T12:26:49.274688",
     "exception": false,
     "start_time": "2020-11-21T12:26:49.239328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Find Images in the Root Directiry and making list of those Images\n",
    "extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "def get_file_list(root_dir):\n",
    "    file_list = []\n",
    "    counter = 1\n",
    "    for root, directories, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(ext in filename for ext in extensions):\n",
    "                file_list.append(os.path.join(root, filename))\n",
    "                counter += 1\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:26:49.325748Z",
     "iopub.status.busy": "2020-11-21T12:26:49.325179Z",
     "iopub.status.idle": "2020-11-21T12:26:49.459852Z",
     "shell.execute_reply": "2020-11-21T12:26:49.459323Z"
    },
    "papermill": {
     "duration": 0.161571,
     "end_time": "2020-11-21T12:26:49.459958",
     "exception": false,
     "start_time": "2020-11-21T12:26:49.298387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path to the datasets\n",
    "root_dir = './Caltech101/Caltech101/train'\n",
    "filenames = sorted(get_file_list(root_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:26:49.525452Z",
     "iopub.status.busy": "2020-11-21T12:26:49.524522Z",
     "iopub.status.idle": "2020-11-21T12:31:38.952250Z",
     "shell.execute_reply": "2020-11-21T12:31:38.952917Z"
    },
    "papermill": {
     "duration": 289.468377,
     "end_time": "2020-11-21T12:31:38.953114",
     "exception": false,
     "start_time": "2020-11-21T12:26:49.484737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "feature_list = []\n",
    "for i in tqdm(range(len(filenames))):\n",
    "    feature_list.append(extract_features(filenames[i], model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:31:39.012423Z",
     "iopub.status.busy": "2020-11-21T12:31:39.011479Z",
     "iopub.status.idle": "2020-11-21T12:31:44.333985Z",
     "shell.execute_reply": "2020-11-21T12:31:44.333177Z"
    },
    "papermill": {
     "duration": 5.353923,
     "end_time": "2020-11-21T12:31:44.334169",
     "exception": false,
     "start_time": "2020-11-21T12:31:38.980246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Making pickle file of filenames and features of each files for future references\n",
    "pickle.dump(feature_list, open('./features-caltech101-resnet.pickle', 'wb'))\n",
    "pickle.dump(filenames, open('./filenames-caltech101.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:32:01.129888Z",
     "iopub.status.busy": "2020-11-21T12:32:01.129256Z",
     "iopub.status.idle": "2020-11-21T12:32:04.770159Z",
     "shell.execute_reply": "2020-11-21T12:32:04.769583Z"
    },
    "papermill": {
     "duration": 3.940644,
     "end_time": "2020-11-21T12:32:04.770295",
     "exception": false,
     "start_time": "2020-11-21T12:32:00.829651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Getting filenames and features from pickle files\n",
    "filenames = pickle.load(open('./filenames-caltech101.pickle', 'rb'))\n",
    "feature_list = pickle.load(open('./features-caltech101-resnet.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:32:04.827891Z",
     "iopub.status.busy": "2020-11-21T12:32:04.827242Z",
     "iopub.status.idle": "2020-11-21T12:32:05.379367Z",
     "shell.execute_reply": "2020-11-21T12:32:05.380005Z"
    },
    "papermill": {
     "duration": 0.583052,
     "end_time": "2020-11-21T12:32:05.380183",
     "exception": false,
     "start_time": "2020-11-21T12:32:04.797131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('./Caltech101/Caltech101/train',\n",
    "                                                   class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:32:05.460902Z",
     "iopub.status.busy": "2020-11-21T12:32:05.459498Z",
     "iopub.status.idle": "2020-11-21T12:32:05.465115Z",
     "shell.execute_reply": "2020-11-21T12:32:05.462853Z"
    },
    "papermill": {
     "duration": 0.048309,
     "end_time": "2020-11-21T12:32:05.465300",
     "exception": false,
     "start_time": "2020-11-21T12:32:05.416991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_generator.filenames[0])\n",
    "print(train_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:32:05.559321Z",
     "iopub.status.busy": "2020-11-21T12:32:05.557404Z",
     "iopub.status.idle": "2020-11-21T12:32:05.560109Z",
     "shell.execute_reply": "2020-11-21T12:32:05.560576Z"
    },
    "papermill": {
     "duration": 0.052323,
     "end_time": "2020-11-21T12:32:05.560692",
     "exception": false,
     "start_time": "2020-11-21T12:32:05.508369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Extracting image name and labels of each Image to make a dataframe that can be used later while using annoy\n",
    "\n",
    "file_names = []\n",
    "labels = []\n",
    "for files in train_generator.filenames:\n",
    "    file = files.split('\\\\')[1]\n",
    "    label = files.split('\\\\')[0]\n",
    "    file_names.append(file)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:32:05.628709Z",
     "iopub.status.busy": "2020-11-21T12:32:05.628087Z",
     "iopub.status.idle": "2020-11-21T12:32:05.630975Z",
     "shell.execute_reply": "2020-11-21T12:32:05.631405Z"
    },
    "papermill": {
     "duration": 0.043888,
     "end_time": "2020-11-21T12:32:05.631519",
     "exception": false,
     "start_time": "2020-11-21T12:32:05.587631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Forming dataframe containing Image Id, Features of Images and Labels of the Images\\\n",
    "df = pd.DataFrame({'img_id':file_names, 'img_repr': feature_list, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:32:05.704717Z",
     "iopub.status.busy": "2020-11-21T12:32:05.704040Z",
     "iopub.status.idle": "2020-11-21T12:32:05.719611Z",
     "shell.execute_reply": "2020-11-21T12:32:05.719120Z"
    },
    "papermill": {
     "duration": 0.062117,
     "end_time": "2020-11-21T12:32:05.719737",
     "exception": false,
     "start_time": "2020-11-21T12:32:05.657620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026955,
     "end_time": "2020-11-21T12:32:05.774043",
     "exception": false,
     "start_time": "2020-11-21T12:32:05.747088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Using Spotify's Annoy for Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:32:05.833620Z",
     "iopub.status.busy": "2020-11-21T12:32:05.833030Z",
     "iopub.status.idle": "2020-11-21T12:32:05.839301Z",
     "shell.execute_reply": "2020-11-21T12:32:05.838838Z"
    },
    "papermill": {
     "duration": 0.037085,
     "end_time": "2020-11-21T12:32:05.839391",
     "exception": false,
     "start_time": "2020-11-21T12:32:05.802306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df['img_repr'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:32:05.928110Z",
     "iopub.status.busy": "2020-11-21T12:32:05.927485Z",
     "iopub.status.idle": "2020-11-21T12:35:18.960239Z",
     "shell.execute_reply": "2020-11-21T12:35:18.960714Z"
    },
    "papermill": {
     "duration": 193.084551,
     "end_time": "2020-11-21T12:35:18.960870",
     "exception": false,
     "start_time": "2020-11-21T12:32:05.876319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "\n",
    "f = len(df['img_repr'][0])\n",
    "t = AnnoyIndex(f, metric='euclidean')\n",
    "\n",
    "for i in tqdm(range(len(feature_list))):\n",
    "    t.add_item(i, feature_list[i])\n",
    "    \n",
    "_ = t.build(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "image_path = './test.jpg'\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "\n",
    "# Expand dimensions to match the model's input shape\n",
    "image = np.expand_dims(image, axis=0)\n",
    "features = model.predict(image)\n",
    "feature_vector = features.flatten()\n",
    "print(len(feature_list))\n",
    "t.unbuid()\n",
    "t.add_item(6162, feature_vector)\n",
    "_ = t.build(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.547824,
     "end_time": "2020-11-21T12:35:20.066072",
     "exception": false,
     "start_time": "2020-11-21T12:35:19.518248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "****Explaination of the above code:****\n",
    "\n",
    "* In this first part, we set the number of dimensions of the space of our net to number of features extracted from image i.e. **100352** and we choose to use an euclidean distance.\n",
    "* Then, in the next step, we create a **6162** items i.e. equal to total number of images, each one with its correspondenly **100352** dimensional vector, which can be also understood as a point in a 100352th dimensional space.\n",
    "* We build then the corresponding net by using 1000 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:35:21.176853Z",
     "iopub.status.busy": "2020-11-21T12:35:21.176003Z",
     "iopub.status.idle": "2020-11-21T12:35:21.178998Z",
     "shell.execute_reply": "2020-11-21T12:35:21.178497Z"
    },
    "papermill": {
     "duration": 0.562569,
     "end_time": "2020-11-21T12:35:21.179103",
     "exception": false,
     "start_time": "2020-11-21T12:35:20.616534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Defining function to get similar images output in dataframe of the base image index we give as parameter\n",
    "\n",
    "def get_similar_images_annoy(img_index):\n",
    "    start = time.time()\n",
    "    base_img_id, base_vector, base_label  = df.iloc[img_index, [0, 1, 2]]\n",
    "    similar_img_ids = t.get_nns_by_item(img_index, 4)\n",
    "    end = time.time()\n",
    "    # Now we want to get the 5 elements sorted by its euclidean distance relative to the image indexed item\n",
    "    print(f'{(end - start) * 1000} ms')\n",
    "    return base_img_id, base_label, df.iloc[similar_img_ids[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:35:22.377070Z",
     "iopub.status.busy": "2020-11-21T12:35:22.376134Z",
     "iopub.status.idle": "2020-11-21T12:35:22.651430Z",
     "shell.execute_reply": "2020-11-21T12:35:22.652510Z"
    },
    "papermill": {
     "duration": 0.919993,
     "end_time": "2020-11-21T12:35:22.652818",
     "exception": false,
     "start_time": "2020-11-21T12:35:21.732825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Querying the AnnoyIndex    \n",
    "base_image, base_label, similar_images_df = get_similar_images_annoy(2200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:35:23.868766Z",
     "iopub.status.busy": "2020-11-21T12:35:23.866795Z",
     "iopub.status.idle": "2020-11-21T12:35:23.871480Z",
     "shell.execute_reply": "2020-11-21T12:35:23.870643Z"
    },
    "papermill": {
     "duration": 0.569381,
     "end_time": "2020-11-21T12:35:23.871635",
     "exception": false,
     "start_time": "2020-11-21T12:35:23.302254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Base Image Id:', base_image)\n",
    "print('Base Image Label:', base_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:35:25.001738Z",
     "iopub.status.busy": "2020-11-21T12:35:25.000733Z",
     "iopub.status.idle": "2020-11-21T12:35:25.005931Z",
     "shell.execute_reply": "2020-11-21T12:35:25.005431Z"
    },
    "papermill": {
     "duration": 0.57229,
     "end_time": "2020-11-21T12:35:25.006036",
     "exception": false,
     "start_time": "2020-11-21T12:35:24.433746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dataframe of similar images\n",
    "similar_images_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.552425,
     "end_time": "2020-11-21T12:35:26.113614",
     "exception": false,
     "start_time": "2020-11-21T12:35:25.561189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Plotting Base and Similar Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:35:27.227171Z",
     "iopub.status.busy": "2020-11-21T12:35:27.226345Z",
     "iopub.status.idle": "2020-11-21T12:35:27.379117Z",
     "shell.execute_reply": "2020-11-21T12:35:27.378103Z"
    },
    "papermill": {
     "duration": 0.709462,
     "end_time": "2020-11-21T12:35:27.379226",
     "exception": false,
     "start_time": "2020-11-21T12:35:26.669764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:35:28.522887Z",
     "iopub.status.busy": "2020-11-21T12:35:28.522003Z",
     "iopub.status.idle": "2020-11-21T12:35:28.525290Z",
     "shell.execute_reply": "2020-11-21T12:35:28.524796Z"
    },
    "papermill": {
     "duration": 0.571606,
     "end_time": "2020-11-21T12:35:28.525388",
     "exception": false,
     "start_time": "2020-11-21T12:35:27.953782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_images(root_dir):\n",
    "    plt.figure(figsize = (16,9))\n",
    "    \n",
    "    plt.subplot(1,4,1)\n",
    "    path = os.path.join(root_dir, base_label, base_image)\n",
    "    image = mpimg.imread(path)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Base Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for i in range(len(similar_images_df)):\n",
    "        path = os.path.join(root_dir, similar_images_df.iloc[i,2],similar_images_df.iloc[i,0])\n",
    "        image = mpimg.imread(path)\n",
    "        plt.subplot(1,4,i+2)\n",
    "        plt.imshow(image)\n",
    "        plt.title('Similar Image')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T12:35:29.654786Z",
     "iopub.status.busy": "2020-11-21T12:35:29.654147Z",
     "iopub.status.idle": "2020-11-21T12:35:29.975013Z",
     "shell.execute_reply": "2020-11-21T12:35:29.975555Z"
    },
    "papermill": {
     "duration": 0.889503,
     "end_time": "2020-11-21T12:35:29.975705",
     "exception": false,
     "start_time": "2020-11-21T12:35:29.086202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = './Caltech101/Caltech101/train/'\n",
    "show_images(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.667108,
     "end_time": "2020-11-21T12:35:31.470787",
     "exception": false,
     "start_time": "2020-11-21T12:35:30.803679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "duration": 539.099979,
   "end_time": "2020-11-21T12:35:34.088762",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-21T12:26:34.988783",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "019f884b25b84896b4475246b5717d51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a329762c3da40e8a2a5a9d926ef0e06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "204cb77bd06645698667a83a1aa52c11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_77308dbe864d4bafb7214c99d6538c9e",
       "max": 6162,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9637709ce17942a2a77966f31ccf3582",
       "value": 6162
      }
     },
     "302a6b2d055249568b15004e3461a063": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "77308dbe864d4bafb7214c99d6538c9e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9637709ce17942a2a77966f31ccf3582": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c8c231d6d65b447f80849b0679cd3ade": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_204cb77bd06645698667a83a1aa52c11",
        "IPY_MODEL_ebe98f9690bd473389f46789c44a3f60"
       ],
       "layout": "IPY_MODEL_1a329762c3da40e8a2a5a9d926ef0e06"
      }
     },
     "ebe98f9690bd473389f46789c44a3f60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_019f884b25b84896b4475246b5717d51",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_302a6b2d055249568b15004e3461a063",
       "value": " 6162/6162 [04:49&lt;00:00, 21.29it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
